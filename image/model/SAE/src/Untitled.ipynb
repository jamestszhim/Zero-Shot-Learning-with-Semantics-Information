{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2048)\n",
      "[1] zsl accuracy for AwA dataset [F >>> S]: 38.71%\n",
      "[2] zsl accuracy for AwA dataset [S >>> F]: 49.92%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nattack_types = [\"bread\", \"dairy\", \"egg\", \"noodles-pasta\", \"seafood\"]\\nC2 = confusion_matrix(np.array(test_labels), np.array(y_hit_k), labels=[0, 1, 3, 6, 8])\\nC2 = C2.astype(\\'float\\') / C2.sum(axis=1)[:, np.newaxis]\\nC2 = np.around(C2, decimals=2)\\ndf_cm = pd.DataFrame(C2, index=attack_types, columns=attack_types)\\nplt.figure(figsize=(10,7))\\nsns.set(font_scale=1.4) # for label size\\nsns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"Blues\") # font size\\n\\nplt.show()\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ld = float(500000)\n",
    "\n",
    "HITK = 2\n",
    "\n",
    "def normalizeFeature(x):\n",
    "    # x = d x N dims (d: feature dimension, N: the number of features)\n",
    "    x = x + 1e-10 # for avoid RuntimeWarning: invalid value encountered in divide\n",
    "    feature_norm = np.sum(x**2, axis=1)**0.5 # l2-norm\n",
    "    feat = x / feature_norm[:, np.newaxis]\n",
    "    return feat\n",
    "\n",
    "def SAE(x, s, ld):\n",
    "    # SAE is Semantic Autoencoder\n",
    "    # INPUTS:\n",
    "    # \tx: d x N data matrix\n",
    "    #\ts: k x N semantic matrix\n",
    "    #\tld: lambda for regularization parameter\n",
    "    #\n",
    "    # OUTPUT:\n",
    "    #\tw: kxd projection matrix\n",
    "\n",
    "    A = np.dot(s, s.transpose())\n",
    "    B = ld * np.dot(x, x.transpose())\n",
    "    C = (1+ld) * np.dot(s, x.transpose())\n",
    "    w = scipy.linalg.solve_sylvester(A,B,C)\n",
    "    print(w.shape)\n",
    "    return w\n",
    "\n",
    "def distCosine(x, y):\n",
    "    xx = np.sum(x**2, axis=1)**0.5\n",
    "    x = x / xx[:, np.newaxis]\n",
    "    yy = np.sum(y**2, axis=1)**0.5\n",
    "    y = y / yy[:, np.newaxis]\n",
    "    dist = 1 - np.dot(x, y.transpose())\n",
    "    return dist\n",
    "\n",
    "\n",
    "\n",
    "def zsl_acc(semantic_predicted, semantic_gt):\n",
    "    # zsl_acc calculates zero-shot classification accruacy\n",
    "    #\n",
    "    # INPUTS:\n",
    "    #\tsemantic_prediced: predicted semantic labels\n",
    "    # \tsemantic_gt: ground truth semantic labels\n",
    "    # \topts: other parameters\n",
    "    #\n",
    "    # OUTPUT:\n",
    "    # \tzsl_accuracy: zero-shot classification accuracy (per-sample)\n",
    "\n",
    "    dist = 1 - distCosine(semantic_predicted, normalizeFeature(semantic_gt.transpose()).transpose())\n",
    "    y_hit_k = np.zeros((dist.shape[0], HITK))\n",
    "    for idx in range(0, dist.shape[0]):\n",
    "        sorted_id = sorted(range(len(dist[idx,:])), key=lambda k: dist[idx,:][k], reverse=True)\n",
    "        y_hit_k[idx,:] = test_classes_id[sorted_id[0:HITK]]\n",
    "    #sns.set()\n",
    "    #C2 = confusion_matrix(test_labels, y_hit_k, labels=[5, 13, 14, 17, 23, 24, 33, 38, 41, 47])\n",
    "    '''\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(C2)\n",
    "    plt.title('Confusion matrix for novel class')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    '''\n",
    "    #ax = plt.subplot()\n",
    "    #sns.heatmap(C2,annot=True, ax = ax)\n",
    "    #labels=[5, 13, 14, 17, 23, 24, 33, 38, 41, 47]\n",
    "    #cmatrix = np.array(confusion_matrix(opts.test_labels, y_hit_k, normalize='true'))\n",
    "    #disp = ConfusionMatrixDisplay(cmatrix, labels)\n",
    "    #fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    #ax.set_title('Confusion Matrix for novel class')   \n",
    "    #disp.plot(xticks_rotation=-45.0, ax=ax, cmap='Blues')\n",
    "    #print(C2)\n",
    "    n = 0\n",
    "    for idx in range(0, dist.shape[0]):\n",
    "        if test_labels[idx] in y_hit_k[idx,:]:\n",
    "            n = n + 1\n",
    "    zsl_accuracy = float(n) / dist.shape[0] * 100\n",
    "    return zsl_accuracy, y_hit_k\n",
    "\n",
    "\n",
    "# for AwA dataset: Perfectly works.\n",
    "'''\n",
    "AWA data details:\n",
    "X_tr: (24295, 1024)\n",
    "X_te: (6108, 1024)\n",
    "S_tr: (24295, 85)\n",
    "test_labels: (6180,)\n",
    "testclasses_id:(10,)\n",
    "S_te_gt: (10, 85)\n",
    "'''\n",
    "\n",
    "'''\n",
    "# AWA\n",
    "opts = parse_args()\n",
    "awa = scipy.io.loadmat('../data/awa_demo_data.mat')\n",
    "train_data = awa['X_tr']\n",
    "test_data = awa['X_te']\n",
    "train_class_attributes_labels_continuous_allset = awa['S_tr']\n",
    "opts.test_labels = awa['test_labels']\n",
    "opts.test_classes_id = awa['testclasses_id']\n",
    "test_class_attributes_labels_continuous = awa['S_te_gt']\n",
    "'''\n",
    "\n",
    "# AWA2_test_attributlabel: (6985, 85)\n",
    "# AWA2_test_continuous_01_attributelabel: (6985, 85)\n",
    "# AWA2_testlabel: (6985,) -> test_labels\n",
    "# AWA2_train_continuous_01_attributelabel: (30337, 85) -> S_tr\n",
    "# AWA2_trainlabel: (30337,)\n",
    "# resnet101_testfeatures: (6985, 2048) -> X_te\n",
    "# resnet101_trainfeatures: (30337, 2048) -> X_tr\n",
    "# AWA2_train_attributelabel: (30337, 85)\n",
    "\n",
    "#opts = parse_args()\n",
    "\n",
    "# food 11 dataset:\n",
    "train_data = np.load('../new_split/resnet101_trainfeatures.npy')\n",
    "test_data = np.load('../new_split/resnet101_testfeatures.npy')\n",
    "train_class_attributes_labels_continuous_allset = np.load('../new_split/Food11_train_Label_attributelabel.npy')\n",
    "test_labels = np.load('../new_split/Food11_testlabel.npy')\n",
    "test_classes_id_list = [0, 1, 3, 6, 8]\n",
    "test_classes_id = np.asarray(test_classes_id_list)\n",
    "test_class_attributes_labels_continuous = np.load('../new_split/S_te_gt_food_Label_normed.npy')\n",
    "\n",
    "'''\n",
    "# AWA2 continuous attributes:\n",
    "train_data = np.load('../data/resnet101_trainfeatures.npy')\n",
    "test_data = np.load('../data/resnet101_testfeatures.npy')\n",
    "train_class_attributes_labels_continuous_allset = np.load('../data/AWA2_train_continuous_01_attributelabel.npy')\n",
    "test_labels = np.load('../data/AWA2_testlabel.npy')\n",
    "test_classes_id_list = [5, 13, 14, 17, 23, 24, 33, 38, 41, 47]\n",
    "test_classes_id = np.asarray(test_classes_id_list)\n",
    "test_class_attributes_labels_continuous = np.load('../data/S_te_gt.npy')\n",
    "'''\n",
    "'''\n",
    "#AWA2 word vector labels:\n",
    "train_data = np.load('../data/resnet101_trainfeatures.npy')\n",
    "test_data = np.load('../data/resnet101_testfeatures.npy')\n",
    "train_class_attributes_labels_continuous_allset = np.load('../data/AWA2_train_Label_attributelabel.npy')\n",
    "test_labels = np.load('../data/AWA2_testlabel.npy')\n",
    "test_classes_id_list = [5, 13, 14, 17, 23, 24, 33, 38, 41, 47]\n",
    "test_classes_id = np.asarray(test_classes_id_list)\n",
    "test_class_attributes_labels_continuous = np.load('../data/S_te_gt_Label.npy')\n",
    "'''\n",
    "'''\n",
    "# AWA2 binary attributes:\n",
    "train_data = np.load('../data/resnet101_trainfeatures.npy')\n",
    "test_data = np.load('../data/resnet101_testfeatures.npy')\n",
    "train_class_attributes_labels_continuous_allset = np.load('../data/AWA2_train_attributelabel.npy')\n",
    "test_labels = np.load('../data/AWA2_testlabel.npy')\n",
    "test_classes_id_list = [5, 13, 14, 17, 23, 24, 33, 38, 41, 47]\n",
    "test_classes_id = np.asarray(test_classes_id_list)\n",
    "test_class_attributes_labels_continuous = np.load('../data/bi_te_att_10_85.npy')\n",
    "'''\n",
    "\n",
    "##### Normalize the data\n",
    "train_data = normalizeFeature(train_data.transpose()).transpose() \n",
    "\n",
    "##### Training\n",
    "# SAE\n",
    "W = SAE(train_data.transpose(), train_class_attributes_labels_continuous_allset.transpose(), ld) \n",
    "\n",
    "##### Test\n",
    "    \n",
    "    \n",
    "# [F --> S], projecting data from feature space to semantic space: 84.68% for AwA dataset\n",
    "semantic_predicted = np.dot(test_data, normalizeFeature(W).transpose())\n",
    "[zsl_accuracy, y_hit_k] = zsl_acc(semantic_predicted, test_class_attributes_labels_continuous)\n",
    "print('[1] zsl accuracy for AwA dataset [F >>> S]: {:.2f}%'.format(zsl_accuracy))\n",
    "\n",
    "#attack_types = [\"persian+cat\", \"hippopotamus\", \"leopard\", \"humpback+whale\",\"seal\",\"chimpanzee\", \"rat\", \"gaint+panda\", \"pig\", \"raccoon\"]\n",
    "#C2 = confusion_matrix(test_labels, y_hit_k, labels=[5, 13, 14, 17, 23, 24, 33, 38, 41, 47])\n",
    "\n",
    "\n",
    "# [S --> F], projecting from semantic to visual space: 84.00% for AwA dataset\n",
    "test_predicted = np.dot(normalizeFeature(test_class_attributes_labels_continuous.transpose()).transpose(), normalizeFeature(W))\n",
    "[zsl_accuracy, y_hit_k] = zsl_acc(test_data, test_predicted)\n",
    "print('[2] zsl accuracy for AwA dataset [S >>> F]: {:.2f}%'.format(zsl_accuracy))\n",
    "'''\n",
    "attack_types = [\"bread\", \"dairy\", \"egg\", \"noodles-pasta\", \"seafood\"]\n",
    "C2 = confusion_matrix(np.array(test_labels), np.array(y_hit_k), labels=[0, 1, 3, 6, 8])\n",
    "C2 = C2.astype('float') / C2.sum(axis=1)[:, np.newaxis]\n",
    "C2 = np.around(C2, decimals=2)\n",
    "df_cm = pd.DataFrame(C2, index=attack_types, columns=attack_types)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"Blues\") # font size\n",
    "\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
